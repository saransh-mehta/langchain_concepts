{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13080603-dc97-4359-8af5-d045e6e44af3",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9583f340-00bd-4667-b90d-042213c5f453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a document to be used for retrieval\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_file = \"~/Desktop/langchain_concepts/hdfc_policy_doc.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d49f418-9b5b-4141-85c2-2b7566c3fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_loader = PyPDFLoader(pdf_file)\n",
    "# will load each page as a document, with lazy loading\n",
    "document_pages = []\n",
    "async for page in pdf_loader.alazy_load():\n",
    "    document_pages.append(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e82ad01-6d4c-4e48-9157-2cd0bcf8a429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(document_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41b9dafa-4cd0-405c-941b-a3fc4d278bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-03-10T17:06:03+05:30', 'author': 'harinis', 'moddate': '2025-03-10T17:06:03+05:30', 'source': '/Users/sarmehta/Desktop/langchain_concepts/hdfc_policy_doc.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}, page_content='Page 1 of 48 \\n \\n \\nPart A \\n(Welcome Letter) \\n<<Date>> \\n<<Policyholder’s Name>>  \\n<<Policyholder’s Address>> \\n<<Policyholder’s Contact Number>> \\n \\nSub: Your Policy no. <<>>-HDFC Life Sampoorn Nivesh Plus \\n \\nDear <<Policyholder’s Name>>,  \\n \\nWe are glad to inform you that your proposal has been accepted and the HDFC Life Sampoorn  Nivesh Plus \\nPolicy (“Policy”) being this Policy, has been issued. We have made every effort to design your Policy in a \\nsimple format. We have highlighted items of importance so that you may recognize them easily. \\n \\nPolicy document: \\nAs evidence of the insurance contract between HDFC Life Insurance Company Limited and you, the Policy is \\nenclosed herewith. Please preserve this document safely and inform your nominees about the same. A copy of \\nyour proposal form and other relevant documents submitted by you is also enclosed  for your information and \\nrecord.  \\n \\nCancellation in the Free-Look Period: \\nIn case you are not agreeable to any of the terms and conditions stated in th e Policy, you have the option to \\nreturn the policy to us for cancellation stating the reasons thereof, within 30 days from the date of receipt of the \\nPolicy whether rece ived electronically or otherwise . On receipt of your letter along with the original \\npolicy(original Policy Document is not required for policies in dematerialised form or where policy is issued \\nonly in electronic form), we shall arrange to refund  the value of Units allocated to you on the date of receipt of \\nrequest plus the unallocated part of the premium plus charges levied by cancellation of Units, subject to \\ndeduction of the proportionate risk premium for the period on cover expenses incurred on medical examination \\nof the proposer and stamp duty charges (if any). \\n \\nContact us: \\nFor any assistance with your policy or services, please call us at 022-68446530 (Mon to Sat – 10 AM to 7 PM \\nIST) or email us at service@hdfclife.com. Please quote your Policy number in all correspondence. Our postal \\naddress for correspondence is as specified below. You may reach out to your Certified Financial Consultant \\n(Insurance Agent) who assisted you with this policy. \\n \\nAgent details: \\nName:<<HDFC BANK, Address: HDFC Bank Ltd, Sandoz House, 2nd Floor, Shiv Sagar Estate, Dr. Annie \\nBesant Road, Worli, Mumbai, Maharashtra -400018 Agent No.:  01546366 License No.:  CA0010 Contact \\nDetails: XXXXXXX>> \\n \\nTo contact us in case of any grievance, please Click here,you may also refer to Part G. \\n \\nYours sincerely, \\n \\n \\nAuthorised Signatory')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_pages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49235168-88e2-44e4-8361-87d1acd55b46",
   "metadata": {},
   "source": [
    "# Chat Model/ LLM Model\n",
    "Here if we have the resources, we can use a local LLM chat model\n",
    "or otherwise use API for LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4fcd928-2e81-45d2-9326-c7a36ab9656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat model for making the retrieval process conversational also\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fc99f6d-4fc8-4254-acd2-82b055075a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nllm_model = HuggingFacePipeline.from_model_id(\\n    model_id=\"HuggingFaceH4/zephyr-7b-beta\",\\n    task=\"text-generation\",\\n    pipeline_kwargs=dict(\\n        max_new_tokens=512,\\n        do_sample=False,\\n        repetition_penalty=1.03,\\n    ),\\n)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this can be used in local if we have memory, otherwise \n",
    "#through API\n",
    "\"\"\"\n",
    "llm_model = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs=dict(\n",
    "        max_new_tokens=512,\n",
    "        do_sample=False,\n",
    "        repetition_penalty=1.03,\n",
    "    ),\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ba0b4e8-ad3d-4401-819f-58f105659ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_model = ChatHuggingFace(llm=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5ae692c-3980-4143-aa16-07ac481ccde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case if not loading model on RAM, can use LLM API as well\n",
    "import os\n",
    "from api_keys import GROQ_API_KEY\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY\n",
    "llm_model = init_chat_model(\"llama3-8b-8192\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb68daa9-0f89-44dc-8c3f-a8058a32d993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with, or would you like to chat?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 12, 'total_tokens': 38, 'completion_time': 0.021666667, 'prompt_time': 0.002390955, 'queue_time': 0.336810913, 'total_time': 0.024057622}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_a97cfe35ae', 'finish_reason': 'stop', 'logprobs': None}, id='run-b06c3ce1-623e-4a13-9d9e-658763b88c0c-0', usage_metadata={'input_tokens': 12, 'output_tokens': 26, 'total_tokens': 38})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.invoke(\"hello there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02e897-f774-45d5-8727-bca1cd09b6a8",
   "metadata": {},
   "source": [
    "# Text Splitter\n",
    "creating text splitter for our document which will break,\n",
    "for document either we can go with Recursive Splitter or also Semantic splitter\n",
    "if the document has content which are more of semantic reference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03fb137-fde5-459c-9635-ee3928cab946",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 300\n",
    "OVERLAP = 30\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = CHUNK_SIZE,\n",
    "                                               chunk_overlap = OVERLAP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8ed5d5-f94a-4be7-b888-06e467f16776",
   "metadata": {},
   "source": [
    "# Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a01f293-4d6b-4715-81e5-06089986a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model for indexing\n",
    "EMBED_DIMS = 768\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "embed_model = HuggingFaceEmbeddings(model_name = \"thenlper/gte-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31018450-e787-41c6-a57c-ff414830d016",
   "metadata": {},
   "source": [
    "# Vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0008578d-4aad-455e-8e57-6bef8cb67cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss index to be used as vector store \n",
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(EMBED_DIMS)\n",
    "vector_store = FAISS(embedding_function = embed_model,\n",
    "                    index = faiss_index,\n",
    "                    docstore = InMemoryDocstore(),\n",
    "                    index_to_docstore_id = {})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ecf56c-5c06-4f62-bb16-570c0065a53e",
   "metadata": {},
   "source": [
    "Here for providing the context to the LLM for retrieval, we have two options,\n",
    "\n",
    "1. Chunk Context -- In this, if we just store the text spliited (chunked) documents in vector store, the vector store retriever would just retrieve the chunk for LLM would have this chunk as the context. It can be used if the chunk size is big enough, and we just need to generate an answer to the query to the user.\n",
    "\n",
    "2. Document context -- How ever, if we need more context, and also need give the user the related document from which the answer is generated, we need to keep the mapping of the vector retrieved chunk to the original document. This can be done by using `ParentDocumentRetriever` in Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31399251-535f-447e-9755-2dfbb75bd0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the chunked documents to the vector store\n",
    "all_splits = text_splitter.split_documents(document_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b517ebc-7045-415c-aa64-5130ad57e7a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-03-10T17:06:03+05:30', 'author': 'harinis', 'moddate': '2025-03-10T17:06:03+05:30', 'source': '/Users/sarmehta/Desktop/langchain_concepts/hdfc_policy_doc.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}, page_content='Details: XXXXXXX>> \\n \\nTo contact us in case of any grievance, please Click here,you may also refer to Part G. \\n \\nYours sincerely, \\n \\n \\nAuthorised Signatory')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "630a9d58-981a-41ad-9b43-ab6513666203",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffd7842-c211-4303-8099-e039083a55cc",
   "metadata": {},
   "source": [
    "# Conversational Graph\n",
    "We will make the RAG application in the LangGraph so as to follow the conversational flow\n",
    "\n",
    "START -> retrieve_node(node1) --> generate_node(node2) --> END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e59c47e-980e-4454-a34e-02197903df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining state class\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72e755df-8ed7-4b3a-b64c-56e087e448a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "47d52831-4ce3-454e-bdfe-b246e8046b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "27a6a37c-c05e-4a9a-810c-28bb2b02b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node 1 for retriving context related to the question\n",
    "def retrieval_node(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"], k=3)\n",
    "    return {\"context\": retrieved_docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3079d7bf-258f-406d-8d78-e3b35c590e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# node 2 for running the LLm with the context\n",
    "# for this we will have to create a prompt first which \n",
    "# will contain the instruction, question, retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0a9a908b-155e-42f8-8552-7d1e508fdf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "05f87937-3f20-4748-8d05-41fe20416006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarmehta/miniconda3/envs/langchain/lib/python3.11/site-packages/langsmith/client.py:253: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e60a9df-b4ee-4bea-ae01-d99f8ea96560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b3875d53-5d89-491f-8bed-b0652f309f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2f9408af-f33f-4427-b2d0-a050a1a65594",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(input_variables=['context', 'question'],\n",
    "                            messages=[\n",
    "                                HumanMessagePromptTemplate(\n",
    "                                    prompt=PromptTemplate(input_variables=['context', 'question'],\n",
    "                                                          template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")\n",
    "                                )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7f183ea6-0109-412f-baf9-b235ec49902c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1325d9cf-e62a-410b-9958-dbebe2dbf97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_node(state: State):\n",
    "    full_context = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": full_context})\n",
    "    #print(messages)\n",
    "    response = llm_model.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b4513a92-03f4-4e36-ab96-8ded35f8200b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1626a4590>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connecting nodes to build graph\n",
    "#START\n",
    "graph_builder.add_edge(START, \"retrieval_node\")\n",
    "\n",
    "# RETRIEVE NODE\n",
    "graph_builder.add_node(\"retrieval_node\", retrieval_node)\n",
    "\n",
    "#edge from retrival node to response node\n",
    "graph_builder.add_edge(\"retrieval_node\", \"response_node\")\n",
    "\n",
    "# RESPONSE NODE\n",
    "graph_builder.add_node(\"response_node\", response_node)\n",
    "\n",
    "#END\n",
    "graph_builder.add_edge(\"response_node\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ba2d4be3-8a0e-4003-b420-bdeca2bf3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d5d01417-907a-4256-bfd2-8b018ddf47cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%{init: {'flowchart': {'curve': 'linear'}}}%%\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tretrieval_node(retrieval_node)\n",
      "\tresponse_node(response_node)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> retrieval_node;\n",
      "\tresponse_node --> __end__;\n",
      "\tretrieval_node --> response_node;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(graph.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2721fce6-d585-4b84-8840-2a645073c43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x162d420d0>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0021fe2-a34b-46fa-9248-fea1164da6ad",
   "metadata": {},
   "source": [
    "# Streaming \n",
    "We can stream the graph in a conversational manner to get information \n",
    "\n",
    "To traverse through the graph, Langchain provides streaming methods\n",
    "`.stream` and `.astream` are sync and async methods for streaming back outputs from a graph run. There are several different modes you can specify when calling these methods (e.g. `graph.stream(..., mode=\"...\")):\n",
    "\n",
    "`\"values\"`: This streams the full value of the state after each step of the graph.\n",
    "\n",
    "`\"updates\"`: This streams the updates to the state after each step of the graph. If multiple updates are made in the same step (e.g. multiple nodes are run) then those updates are streamed separately.\n",
    "\n",
    "`\"custom\"`: This streams custom data from inside your graph nodes.\n",
    "\n",
    "`\"messages\"`: This streams LLM tokens and metadata for the graph node where LLM is invoked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a6f2565a-f865-494f-abdc-97c618166b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6203c3d1-e626-4854-924a-42abcbc39492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I don\\'t know the answer to that question. The provided context does not mention or define \"Task Decomposition\".'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ba27700-b365-41f5-82ac-13e8019a24c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"What is HDFC insurance about?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "819b2f24-3452-4ccc-bd7c-cca4ae1dea07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HDFC insurance appears to be a life insurance company offering various policies, including Unit Linked Non-Participating Individual Life Insurance Savings Policies. These policies are designed to provide financial protection and savings benefits to policyholders.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8cdf6ee-3800-43e1-a455-003d6e7fd5ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is HDFC insurance about?',\n",
       " 'context': [Document(id='9ead75b5-cb61-4d1d-a58f-1143c89bf33c', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-03-10T17:06:03+05:30', 'author': 'harinis', 'moddate': '2025-03-10T17:06:03+05:30', 'source': '/Users/sarmehta/Desktop/langchain_concepts/hdfc_policy_doc.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}, page_content='IST) or email us at service@hdfclife.com. Please quote your Policy number in all correspondence. Our postal \\naddress for correspondence is as specified below. You may reach out to your Certified Financial Consultant \\n(Insurance Agent) who assisted you with this policy. \\n \\nAgent details:'),\n",
       "  Document(id='ae96cbd0-f50a-4830-b1e0-fe859dcc570c', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-03-10T17:06:03+05:30', 'author': 'harinis', 'moddate': '2025-03-10T17:06:03+05:30', 'source': '/Users/sarmehta/Desktop/langchain_concepts/hdfc_policy_doc.pdf', 'total_pages': 48, 'page': 0, 'page_label': '1'}, page_content='simple format. We have highlighted items of importance so that you may recognize them easily. \\n \\nPolicy document: \\nAs evidence of the insurance contract between HDFC Life Insurance Company Limited and you, the Policy is'),\n",
       "  Document(id='39c51b0c-ff6e-4172-91b7-fe2a0769764e', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-03-10T17:06:03+05:30', 'author': 'harinis', 'moddate': '2025-03-10T17:06:03+05:30', 'source': '/Users/sarmehta/Desktop/langchain_concepts/hdfc_policy_doc.pdf', 'total_pages': 48, 'page': 2, 'page_label': '3'}, page_content='Company Limited  (“HDFC Life”)  (‘We’/ ‘Company’) and the Policyholder (‘You’) as described in the \\nPolicy Schedule given below. This Policy is based on the Proposal made by the within named Policyholder'),\n",
       "  Document(id='25b1d1c7-dc0b-460f-9dd8-b1d0fbb48a8c', metadata={'producer': 'Microsoft® Word LTSC', 'creator': 'Microsoft® Word LTSC', 'creationdate': '2025-03-10T17:06:03+05:30', 'author': 'harinis', 'moddate': '2025-03-10T17:06:03+05:30', 'source': '/Users/sarmehta/Desktop/langchain_concepts/hdfc_policy_doc.pdf', 'total_pages': 48, 'page': 2, 'page_label': '3'}, page_content='COMPLETELY OR PARTIALLY TILL THE END OF THE FIFTH YEAR \\n \\nYour Policy is a << regular/ limited/single>> Premium paying Unit Linked Non-Participating Individual Life \\nInsurance Savings Policy. This document is the evidence of a contract between HDFC Life Insurance')],\n",
       " 'answer': 'HDFC insurance appears to be a life insurance company offering various policies, including Unit Linked Non-Participating Individual Life Insurance Savings Policies. These policies are designed to provide financial protection and savings benefits to policyholders.'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "416891c1-3982-4a34-9d49-e59ae174ad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AIMessage\n",
    "def run_graph(question: str):\n",
    "    for event in graph.stream(\n",
    "        {\"question\": question},\n",
    "    stream_mode = \"values\"):\n",
    "        #print(event)\n",
    "        final_result = event.get(\"answer\")\n",
    "        if final_result:\n",
    "            print(\"Result: {}\".format(final_result))\n",
    "        \"\"\"\n",
    "        for value in event.values():\n",
    "            # printing latest message in state\n",
    "            # here, be careful not the return, as it will break the event cycle\n",
    "            # and the process will stop after passing through first node\n",
    "\n",
    "            #also we don't need intermediate tool outputs\n",
    "            print(value)\n",
    "            node_result = value[\"answer\"][-1]\n",
    "            print(\"Chat: {}\".format(node_result.content))\n",
    "            if isinstance(node_result, (HumanMessage, AIMessage)) and node_result.content:\n",
    "                print(\"Chat: {}\".format(node_result.content))\n",
    "            \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "71c20962-a354-4488-995b-7b772fb3ed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what is a ship\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: I don't know. The provided context is about scheduled airlines and insurance policy definitions, and it doesn't mention ships or vessels.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  what does life assured mean in the policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: In the policy, \"Life Assured\" refers to the person whose life the contingent events must occur for the benefits to be payable. This person may be different from the policyholder.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  How can i cancel this policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: You can cancel the policy by returning it to us within 30 days from the date of receipt, stating the reasons for cancellation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  is there any lock in period in the policy?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Yes, there is a lock-in period of five consecutive completed years from the Policy Commencement Date, during which the proceeds of the policies cannot be paid by the insurer. During this period, the policy will remain in discontinuance fund till the end of the lock-in period.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  who is Joe Biden?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: I don't know. The provided context appears to be related to a life insurance policy and does not mention Joe Biden, who is a public figure and the 46th President of the United States.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[133], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# running the chat bot, \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m----> 3\u001b[0m     user_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser: \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.11/site-packages/ipykernel/kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1285\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1286\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1287\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/langchain/lib/python3.11/site-packages/ipykernel/kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  q\n"
     ]
    }
   ],
   "source": [
    "# running the chat bot, \n",
    "while True:\n",
    "    user_input = str(input(\"User: \"))\n",
    "    if user_input.lower() in [\"quit\", \"q\", \"exit\"]:\n",
    "        break\n",
    "    run_graph(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0287f57a-2b90-4304-90e2-4be95a400511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
